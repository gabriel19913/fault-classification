{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from sktime.transformations.panel.rocket import Rocket, MiniRocketMultivariate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from glob import glob\n",
    "import time\n",
    "from noise import decompress_pickle\n",
    "INPUT_DATA_PATH = '../input-data/'\n",
    "MODEL_PATH = './models/'\n",
    "data = decompress_pickle(INPUT_DATA_PATH + 'cycle_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_folds(cycle, train_test, X_y, v_i):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        cycle      : which cycle, ex.: 'cycle_1' (1, 2, 4, 8, 16, 32)\n",
    "        train_test : if it is the train ot test set, ex: 'train' (train, test)\n",
    "        X_y        : if it is the X or y set, ex.: 'X' (X, y)\n",
    "        v_i        : if it is a voltage or current signal, ex.: 'i' (v, i)\n",
    "    Return:\n",
    "        list : each fold is in a position.\n",
    "    \"\"\"\n",
    "    paths = list(map(lambda x: x.split('.pbz2')[0], glob(INPUT_DATA_PATH + \n",
    "                                                         f'folds/{v_i}/{cycle}/{X_y}_{train_test}_fold_[0-9]*.pbz2')))\n",
    "    paths.sort(key = lambda x: int(x.split('_')[-1]))\n",
    "    data_list = []\n",
    "    for path in paths:\n",
    "        folder_pos = int(path.split('/')[-1].split('_')[-1]) - 1\n",
    "        fold = decompress_pickle(path)\n",
    "        data_list.insert(folder_pos, fold)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(X):\n",
    "    max = np.max(X)\n",
    "    min = np.abs(np.min(X))\n",
    "    if max > min:\n",
    "        return max\n",
    "    else:\n",
    "        return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataframe(data):\n",
    "    cols = int(data.shape[0] / 4)\n",
    "    shaped_data = data.reshape((4, cols)).T\n",
    "    s1 = pd.Series(shaped_data[:, 0])\n",
    "    s2 = pd.Series(shaped_data[:, 1])\n",
    "    s3 = pd.Series(shaped_data[:, 2])\n",
    "    s4 = pd.Series(shaped_data[:, 3])\n",
    "    dicio = {'A': [], 'B': [], 'C': [], 'Z': []}\n",
    "    dicio['A'].append(s1)\n",
    "    dicio['B'].append(s2)\n",
    "    dicio['C'].append(s3)\n",
    "    dicio['Z'].append(s4)\n",
    "    return pd.DataFrame(dicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = decompress_pickle(INPUT_DATA_PATH + f'folds/i/cycle_1/X_train')\n",
    "y_train = decompress_pickle(INPUT_DATA_PATH + f'folds/i/cycle_1/y_train')\n",
    "X_val = decompress_pickle(INPUT_DATA_PATH + f'folds/i/cycle_1/X_val')\n",
    "y_val = decompress_pickle(INPUT_DATA_PATH + f'folds/i/cycle_1/y_val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_list = [0, 0, 0, 0]\n",
    "for k, v in {'A': 0, 'B': 1, 'C': 2, 'Z': 3}.items():\n",
    "    for row in X_train[k]:\n",
    "        max_value = find_max(row)\n",
    "        if max_value > max_list[v]:\n",
    "            max_list[v] = max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[6075.605580855044, 6077.654717323059, 6068.883200964617, 3100.6294160039506]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train.copy()\n",
    "X_train_norm['A'] = X_train_norm['A'] / max_list[0]\n",
    "X_train_norm['B'] = X_train_norm['B'] / max_list[1]\n",
    "X_train_norm['C'] = X_train_norm['C'] / max_list[2]\n",
    "X_train_norm['Z'] = X_train_norm['Z'] / max_list[3]\n",
    "\n",
    "X_val_norm = X_val.copy()\n",
    "X_val_norm['A'] = X_val_norm['A'] / max_list[0]\n",
    "X_val_norm['B'] = X_val_norm['B'] / max_list[1]\n",
    "X_val_norm['C'] = X_val_norm['C'] / max_list[2]\n",
    "X_val_norm['Z'] = X_val_norm['Z'] / max_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list2 = [0, 0, 0, 0]\n",
    "for k, v in {'A': 0, 'B': 1, 'C': 2, 'Z': 3}.items():\n",
    "    for row in X_train_norm[k]:\n",
    "        max_value = find_max(row)\n",
    "        if max_value > max_list2[v]:\n",
    "            max_list2[v] = max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "max_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_cycle_1 = open_folds('cycle_1', 'train', 'X', 'i')\n",
    "train_y_cycle_1 = open_folds('cycle_1', 'train', 'y', 'i')\n",
    "test_X_cycle_1 = open_folds('cycle_1', 'test', 'X', 'i')\n",
    "test_y_cycle_1 = open_folds('cycle_1', 'test', 'y', 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10000\n",
    "minirocket = MiniRocketMultivariate(num_features=num_features)\n",
    "minirocket.fit(X_train_norm)\n",
    "X_val_transform = minirocket.transform(X_val_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia em cada fold:\n [100. 100. 100. 100. 100. 100. 100. 100. 100. 100.]\n\nMédia da acurácia: 100.00%\nDesvio padrão da acurácia: 0.00%)\nTempo necessário para treinamento 45.84214758872986 segundos\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "count = -1\n",
    "s = time.time()\n",
    "for X_tr, y_tr, X_te, y_te in zip(train_X_cycle_1, train_y_cycle_1,\n",
    "                                  test_X_cycle_1, test_y_cycle_1):\n",
    "\n",
    "    # Normalização\n",
    "    X_tr_norm = X_tr.copy()\n",
    "    X_tr_norm['A'] = X_tr_norm['A'] / max_list[0]\n",
    "    X_tr_norm['B'] = X_tr_norm['B'] / max_list[1]\n",
    "    X_tr_norm['C'] = X_tr_norm['C'] / max_list[2]\n",
    "    X_tr_norm['Z'] = X_tr_norm['Z'] / max_list[3]\n",
    "\n",
    "    X_te_norm = X_te.copy()\n",
    "    X_te_norm['A'] = X_te_norm['A'] / max_list[0]\n",
    "    X_te_norm['B'] = X_te_norm['B'] / max_list[1]\n",
    "    X_te_norm['C'] = X_te_norm['C'] / max_list[2]\n",
    "    X_te_norm['Z'] = X_te_norm['Z'] / max_list[3]\n",
    "\n",
    "    # Treinamento\n",
    "    X_tr_transform = minirocket.transform(X_tr_norm)\n",
    "    X_te_transform = minirocket.transform(X_te_norm)\n",
    "    clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    clf.fit(X_tr_transform, y_tr)\n",
    "\n",
    "    # Avaliação do modelo\n",
    "    score = clf.score(X_te_transform, y_te)\n",
    "    scores.append(score)\n",
    "    if len(scores) == 1:\n",
    "        pickle.dump(clf, open(MODEL_PATH + 'minirocket_model_cycle_1.pkl', 'wb'))\n",
    "        # compressed_pickle(MODEL_PATH + 'rocket_model_cycle_1', clf)\n",
    "    else:\n",
    "        if score > scores[count]:\n",
    "            pickle.dump(clf, open(MODEL_PATH + 'minirocket_model_cycle_1.pkl', 'wb'))\n",
    "            # compressed_pickle(MODEL_PATH + 'rocket_model_cycle_1', clf)\n",
    "    count += 1\n",
    "e = time.time()\n",
    "final_scores = np.array(scores)\n",
    "print(f'Acurácia em cada fold:\\n {np.round(final_scores * 100, decimals=2)}')\n",
    "print(f'\\nMédia da acurácia: {np.mean(final_scores) * 100:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {np.std(final_scores) * 100:.2f}%)')\n",
    "print(f'Tempo necessário para treinamento {e-s} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH + 'minirocket_model_cycle_1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.score(X_val_transform, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_kernels = 10000\n",
    "rocket = Rocket(num_kernels=num_kernels)\n",
    "rocket.fit(X_train_norm)\n",
    "X_val_transform = rocket.transform(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia em cada fold:\n [100. 100. 100. 100. 100. 100. 100. 100. 100. 100.]\n\nMédia da acurácia: 100.00%\nDesvio padrão da acurácia: 0.00%)\nTempo necessário para treinamento 473.60908007621765 segundos\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "count = -1\n",
    "s = time.time()\n",
    "for X_tr, y_tr, X_te, y_te in zip(train_X_cycle_1, train_y_cycle_1,\n",
    "                                  test_X_cycle_1, test_y_cycle_1):\n",
    "\n",
    "    # Normalização\n",
    "    X_tr_norm = X_tr.copy()\n",
    "    X_tr_norm['A'] = X_tr_norm['A'] / max_list[0]\n",
    "    X_tr_norm['B'] = X_tr_norm['B'] / max_list[1]\n",
    "    X_tr_norm['C'] = X_tr_norm['C'] / max_list[2]\n",
    "    X_tr_norm['Z'] = X_tr_norm['Z'] / max_list[3]\n",
    "\n",
    "    X_te_norm = X_te.copy()\n",
    "    X_te_norm['A'] = X_te_norm['A'] / max_list[0]\n",
    "    X_te_norm['B'] = X_te_norm['B'] / max_list[1]\n",
    "    X_te_norm['C'] = X_te_norm['C'] / max_list[2]\n",
    "    X_te_norm['Z'] = X_te_norm['Z'] / max_list[3]\n",
    "\n",
    "    # Treinamento\n",
    "    X_tr_transform = rocket.transform(X_tr_norm)\n",
    "    X_te_transform = rocket.transform(X_te_norm)\n",
    "    clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "    clf.fit(X_tr_transform, y_tr)\n",
    "\n",
    "    # Avaliação do modelo\n",
    "    score = clf.score(X_te_transform, y_te)\n",
    "    scores.append(score)\n",
    "    if len(scores) == 1:\n",
    "        pickle.dump(clf, open(MODEL_PATH + 'rocket_model_cycle_1.pkl', 'wb'))\n",
    "        # compressed_pickle(MODEL_PATH + 'rocket_model_cycle_1', clf)\n",
    "    else:\n",
    "        if score > scores[count]:\n",
    "            pickle.dump(clf, open(MODEL_PATH + 'rocket_model_cycle_1.pkl', 'wb'))\n",
    "            # compressed_pickle(MODEL_PATH + 'rocket_model_cycle_1', clf)\n",
    "    count += 1\n",
    "e = time.time()\n",
    "final_scores = np.array(scores)\n",
    "print(f'Acurácia em cada fold:\\n {np.round(final_scores * 100, decimals=2)}')\n",
    "print(f'\\nMédia da acurácia: {np.mean(final_scores) * 100:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {np.std(final_scores) * 100:.2f}%)')\n",
    "print(f'Tempo necessário para treinamento {e-s} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH + 'rocket_model_cycle_1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.score(X_val_transform, y_val)"
   ]
  },
  {
   "source": [
    "# Using pipelines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38764bitmestrado93452fa44c9a400d9f916e3ee858cfd5",
   "display_name": "Python 3.8.7 64-bit ('mestrado')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}