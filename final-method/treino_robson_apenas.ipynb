{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from itertools import product\n",
    "from noise import add_noise\n",
    "import mat73\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from training_sktime import normalizing\n",
    "import numpy as np \n",
    "import random\n",
    "from noise import compressed_pickle, decompress_pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "INPUT_DATA_PATH = '../input-data/'\n",
    "MODEL_PATH = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input-data/dados_robson/Sinais_Robson/'\n",
    "files = glob(path + '*.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparo = [file for file in files if 'disparo' in file ][0]\n",
    "for i, file in enumerate(files):\n",
    "    if 'disparo' in file:\n",
    "        disparo = file\n",
    "        del files[i]\n",
    "distance = range(3)\n",
    "resistance = range(3)\n",
    "compensation = range(4)\n",
    "angle = range(19)\n",
    "\n",
    "indexes = list(product(distance, resistance, compensation, angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(i):\n",
    "    if i[0] == 0:\n",
    "        return '20'\n",
    "    elif i[0] == 1:\n",
    "        return '150'\n",
    "    else:\n",
    "        return '280'\n",
    "\n",
    "def get_resistance(i):\n",
    "    if i[1] == 0:\n",
    "        return '1'\n",
    "    elif i[1] == 1:\n",
    "        return '50'\n",
    "    else:\n",
    "        return '100'\n",
    "\n",
    "def get_compensation(i):\n",
    "    if i[2] == 0:\n",
    "        return '0.4'\n",
    "    elif i[2] == 1:\n",
    "        return '0.5'\n",
    "    elif i[2] == 2:\n",
    "        return '0.6'\n",
    "    else:\n",
    "        return '0.7'\n",
    "\n",
    "def get_angle(i):\n",
    "    return str(i[3] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_dict = {}\n",
    "for i, item in enumerate(sio.loadmat(disparo)['Flt_trip']):\n",
    "    value = np.where(item[:-1] != item[1:])[0][0]\n",
    "    angle_dict[i] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_dict = {'32': 8, '64': 4, '128': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = []\n",
    "for file in files:\n",
    "    data = mat73.loadmat(file)\n",
    "    fault_type = file.split('_')[-1].split('.')[0]\n",
    "    signal = data[f'I_{fault_type}']\n",
    "    final_dict_signal = {}\n",
    "    # samples = [indexes[i] for i in random.sample(range(684), 94)]\n",
    "    for i in indexes:\n",
    "        phase = signal[:,:, i[0], i[1], i[2], i[3]]\n",
    "        index = angle_dict[i[3]]\n",
    "        distance = get_distance(i)\n",
    "        resistance = get_resistance(i)\n",
    "        compensation = get_compensation(i)\n",
    "        angle = get_angle(i)\n",
    "        fault = fault_type.replace('G', 'T')\n",
    "        final_dict_signal = {'distance': distance, 'resistance': resistance,\n",
    "                                'compensation': compensation, 'angle': angle, 'fault_type': fault}\n",
    "\n",
    "        # Subdivide sinal com ciclos pós falta\n",
    "        for c, v in cycle_dict.items():\n",
    "            detected_signal = phase[index-64:index+v]\n",
    "            phase_a = add_noise(detected_signal[:,0], 60)\n",
    "            phase_b = add_noise(detected_signal[:,1], 60)\n",
    "            phase_c = add_noise(detected_signal[:,2], 60)\n",
    "            phase_z = phase_a + phase_b + phase_c\n",
    "            \n",
    "            final_detected = np.vstack((phase_a, phase_b, phase_c, phase_z)).flatten()\n",
    "            final_dict_signal.update({f'i_cycle_{c}': final_detected})\n",
    "\n",
    "        signals.append(final_dict_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataframe(data):\n",
    "    cols = int(data.shape[0] / 4)\n",
    "    shaped_data = data.reshape((4, cols)).T\n",
    "    s1 = pd.Series(shaped_data[:, 0])\n",
    "    s2 = pd.Series(shaped_data[:, 1])\n",
    "    s3 = pd.Series(shaped_data[:, 2])\n",
    "    s4 = pd.Series(shaped_data[:, 3])\n",
    "    dicio = {'A': [], 'B': [], 'C': [], 'Z': []}\n",
    "    dicio['A'].append(s1)\n",
    "    dicio['B'].append(s2)\n",
    "    dicio['C'].append(s3)\n",
    "    dicio['Z'].append(s4)\n",
    "    return pd.DataFrame(dicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(signal_type, cycle_name):\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "    for d in signals:\n",
    "        data_list.append(format_dataframe(d[f'{signal_type}_{cycle_name}']))\n",
    "        target_list.append(d['fault_type'])\n",
    "    X = pd.concat(data_list).reset_index(drop=True)\n",
    "    y = np.array(target_list)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,\n",
    "                                                        random_state=42, shuffle=True)\n",
    "    compressed_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal_type}/{cycle_name}/' + 'X_train', X_train)\n",
    "    compressed_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal_type}/{cycle_name}/' + 'y_train', y_train)\n",
    "    compressed_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal_type}/{cycle_name}/' + 'X_val', X_test)\n",
    "    compressed_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal_type}/{cycle_name}/' + 'y_val', y_test)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_folds(signal_type, cycle_name):\n",
    "    X_train, y_train = open_data(signal_type, cycle_name)\n",
    "    data_folds_path = INPUT_DATA_PATH + f'folds-robson-completo/{signal_type}/{cycle_name}/'\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    for fold, (tr, te) in enumerate(kf.split(X_train, y_train), start=1):\n",
    "        X_tr, X_te = X_train.iloc[tr, :], X_train.iloc[te, :]\n",
    "        y_tr, y_te = y_train[tr], y_train[te]\n",
    "        compressed_pickle(data_folds_path + f'X_train_fold_{fold}', X_tr)\n",
    "        compressed_pickle(data_folds_path + f'X_test_fold_{fold}', X_te)\n",
    "        compressed_pickle(data_folds_path + f'y_train_fold_{fold}', y_tr)\n",
    "        compressed_pickle(data_folds_path + f'y_test_fold_{fold}', y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_list = ['cycle_32', 'cycle_64', 'cycle_128']\n",
    "\n",
    "for cycle_name in cycle_list:\n",
    "    save_folds('i', cycle_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from itertools import product\n",
    "from noise import add_noise, decompress_pickle\n",
    "import mat73\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from training_sktime import normalizing, format_dataframe\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import time\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_folds(cycle, train_test, X_y, v_i):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        cycle      : which cycle, ex.: 'cycle_1' (1, 2, 4, 8, 16, 32, 64, 128...)\n",
    "        train_test : if it is the train ot test set, ex: 'train' (train, test)\n",
    "        X_y        : if it is the X or y set, ex.: 'X' (X, y)\n",
    "        v_i        : if it is a voltage or current signal, ex.: 'i' (v, i)\n",
    "    Return:\n",
    "        list : each fold is in a position.\n",
    "    \"\"\"\n",
    "    paths_robson = list(map(lambda x: x.split('.pbz2')[0],\n",
    "                            glob(INPUT_DATA_PATH + f'folds-robson-completo/{v_i}/{cycle}/{X_y}_{train_test}_fold_[0-9]*.pbz2')))\n",
    "    paths_robson.sort(key = lambda x: int(x.split('_')[-1]))\n",
    "    data_list = []\n",
    "    for path in paths_robson:\n",
    "        folder_pos = int(path.split('/')[-1].split('_')[-1]) - 1\n",
    "        fold = decompress_pickle(path)\n",
    "        data_list.insert(folder_pos, fold)\n",
    "    return data_list\n",
    "\n",
    "def generate_title(cycle, model_name):\n",
    "    title = cycle.split('_')[-1]\n",
    "    if title != '1':\n",
    "        title = f'{model_name.title()} e 1/{title} ciclo pós falta'\n",
    "    else:\n",
    "        title = f'{model_name.title()} e 1 ciclo pós falta'\n",
    "    return title\n",
    "\n",
    "def evaluating_model(model, transformation, X_test, y_test, cycle, scores, count, max_list, model_name='model', save=None):\n",
    "    # Evaluating model\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    if save and (\n",
    "        len(scores) != 1 and score > scores[count] or len(scores) == 1\n",
    "    ):\n",
    "        pickle.dump(transformation, open(MODEL_PATH + f'novo_treino_{model_name}_{cycle}.pkl', 'wb'))\n",
    "        pickle.dump(model, open(MODEL_PATH + f'novo_treino_{model_name}_classifier_{cycle}.pkl', 'wb'))\n",
    "        pickle.dump(max_list, open(MODEL_PATH + f'novo_treino_{model_name}_{cycle}_max_values.pkl', 'wb'))\n",
    "    return scores\n",
    "\n",
    "def print_results(cycle, model_name, scores, end_time, start_time, save=None):\n",
    "    folds_labels = [f'- Fold {i}' for i in range(1, 11)]\n",
    "    f = open(f'novo_treino_{model_name}_report.txt','a') if save else save\n",
    "    title = generate_title(cycle, model_name)\n",
    "    print('\\nAcurácia em cada fold:\\n')\n",
    "    for k, v in dict(zip(folds_labels, np.round(scores * 100, decimals=2))).items():\n",
    "        print(f'{k:<7}: {v:^7.2f}%')\n",
    "    print('\\nO resulto final obtido foi:\\n')\n",
    "    print(f'- Média da acurácia: {np.mean(scores) * 100:.2f}%')\n",
    "    print(f'- Desvio padrão da acurácia: {np.std(scores) * 100:.2f}%')\n",
    "    print(f'- Tempo necessário para treinamento: {np.round(end_time - start_time, 3)} segundos')\n",
    "    \n",
    "def kfold(train_X, train_y, test_X, test_y, model, cycle, max_list, model_name='',\n",
    "          transformation=None, save=None):\n",
    "    scores = []\n",
    "    s = time.time()\n",
    "    for count, (X_tr, y_tr, X_te, y_te) in enumerate(zip(train_X, train_y, test_X, test_y),\n",
    "                                                     start=-1):\n",
    "        X_tr_norm = normalizing(X_tr, max_list)\n",
    "        X_te_norm = normalizing(X_te, max_list)\n",
    "\n",
    "        # Transforming data\n",
    "        if transformation:\n",
    "            X_tr_transform = transformation.transform(X_tr_norm)\n",
    "            X_te_transform = transformation.transform(X_te_norm)\n",
    "        else:\n",
    "            X_tr_transform = X_tr_norm.copy()\n",
    "            X_te_transform = X_te_norm.copy()\n",
    "\n",
    "        model.fit(X_tr_transform, y_tr)\n",
    "        scores = evaluating_model(model, transformation, X_te_transform, y_te, cycle, scores,\n",
    "                                  count, max_list, model_name, save)\n",
    "\n",
    "    e = time.time()\n",
    "    final_scores = np.array(scores)\n",
    "    print_results(cycle, model_name, final_scores, e, s, save)\n",
    "    return np.mean(scores) * 100, np.round(e - s, 3)\n",
    "\n",
    "def validating(X_val, y_val, model_name, cycle, max_list, save=None):\n",
    "    s = time.time()\n",
    "    with open(MODEL_PATH + f'novo_treino_{model_name}_classifier_{cycle}.pkl', 'rb') as f:\n",
    "        best_model = pickle.load(f)\n",
    "    val_score = best_model.score(X_val, y_val)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    e = time.time()\n",
    "    f = open(f'novo_treino_{model_name}_report.txt','a') if save else save\n",
    "    print(f'- Acurácia no conjunto de validação: {val_score * 100:.2f}%')\n",
    "    print(f'- Tempo necessário para predição do conjunto de validação: {np.round(e - s, 3)} segundos')\n",
    "    return y_pred, val_score * 100, np.round(e - s, 3)\n",
    "\n",
    "def generate_confusion_matrix(y_val, y_pred, image_path, filename, title='', colorscale='blues',\n",
    "                              width=500, height=500):\n",
    "    data = {'Real':    y_val,\n",
    "            'Predito': y_pred}\n",
    "    df = pd.DataFrame(data, columns=['Real','Predito'])\n",
    "    confusion_matrix = pd.crosstab(df['Real'], df['Predito'], rownames=['Real'],\n",
    "                                   colnames=['Predito'], margins = True)\n",
    "    cm = confusion_matrix.drop('All', axis=1).drop('All', axis=0)\n",
    "    # Inverte rows because create_annotated_heatmap creates matrix in inverted order\n",
    "    c = cm.values[::-1]\n",
    "    x = list(cm.index)\n",
    "    y = x[::-1]\n",
    "    c_text = [[str(y) for y in x] for x in c]\n",
    "    fig = ff.create_annotated_heatmap(c, x=x, y=y, annotation_text=c_text, colorscale=colorscale)\n",
    "    # add title\n",
    "    fig.update_layout(title_text=f'<i><b>Matriz de Confusão {title}</b></i>',\n",
    "                      title_x=0.5, autosize=False, width=width, height=height,)\n",
    "    # add custom xaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14), x=0.5, y=-0.12, showarrow=False,\n",
    "                            text=\"Valores Preditos\", xref=\"paper\", yref=\"paper\"))\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=14), x=-0.2, y=0.5, textangle=270,\n",
    "                            showarrow=False, text=\"Valores Reais\", xref=\"paper\", yref=\"paper\"))\n",
    "    fig.write_image(image_path + filename + '.svg')\n",
    "\n",
    "def find_max(X):\n",
    "    max = np.max(X)\n",
    "    min = np.abs(np.min(X))\n",
    "    if max > min:\n",
    "        return max\n",
    "    else:\n",
    "        return min\n",
    "\n",
    "def find_max_value(X):\n",
    "    # Finding max value in by phase in training set to normalize signals\n",
    "    max_list = [0, 0, 0, 0]\n",
    "    for k, v in {'A': 0, 'B': 1, 'C': 2, 'Z': 3}.items():\n",
    "        for row in X[k]:\n",
    "            max_value = find_max(row)\n",
    "            if max_value > max_list[v]:\n",
    "                max_list[v] = max_value\n",
    "    return max_list\n",
    "\n",
    "def training(signal, cycle, model, model_name='', transformation=None, save=None):\n",
    "    X_train = decompress_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal}/{cycle}/X_train')\n",
    "    X_val = decompress_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal}/{cycle}/X_val')\n",
    "    y_val = decompress_pickle(INPUT_DATA_PATH + f'folds-robson-completo/{signal}/{cycle}/y_val')\n",
    "\n",
    "    max_list = find_max_value(X_train)\n",
    "    X_train_norm = normalizing(X_train, max_list)\n",
    "    X_val_norm = normalizing(X_val, max_list)\n",
    "        \n",
    "    if transformation:\n",
    "        transformation.fit(X_train_norm)\n",
    "        X_val_transform = transformation.transform(X_val_norm)\n",
    "    else:\n",
    "        X_val_transform = X_val_norm.copy()\n",
    "\n",
    "    # Opening the folds and saving as lists for training and testing \n",
    "    train_X = open_folds(cycle, 'train', 'X', signal)\n",
    "    train_y = open_folds(cycle, 'train', 'y', signal)\n",
    "    test_X = open_folds(cycle, 'test', 'X', signal)\n",
    "    test_y = open_folds(cycle, 'test', 'y', signal)\n",
    "    mean_acc, train_time = kfold(train_X, train_y, test_X, test_y, model, cycle, max_list, model_name, transformation, save)\n",
    "    y_pred, val_acc, val_time = validating(X_val_transform, y_val, model_name, cycle, max_list, save)\n",
    "    # title = generate_title(cycle, model_name)\n",
    "    # generate_confusion_matrix(y_val, y_pred, 'figs_cm/new_dataset/', f'{cycle}_{model_name}', title=title)\n",
    "    # print(f'Finalizado treinamento para {title}!')\n",
    "    return mean_acc, val_acc, train_time, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Treinando com 10000 features (default)\n",
      "\n",
      "---\n",
      "\n",
      "Acurácia em cada fold:\n",
      "\n",
      "- Fold 1:  46.72 %\n",
      "- Fold 2:  51.09 %\n",
      "- Fold 3:  52.65 %\n",
      "- Fold 4:  49.54 %\n",
      "- Fold 5:  51.19 %\n",
      "- Fold 6:  48.99 %\n",
      "- Fold 7:  47.90 %\n",
      "- Fold 8:  46.80 %\n",
      "- Fold 9:  47.71 %\n",
      "- Fold 10:  46.98 %\n",
      "\n",
      "O resulto final obtido foi:\n",
      "\n",
      "- Média da acurácia: 48.96%\n",
      "- Desvio padrão da acurácia: 1.99%\n",
      "- Tempo necessário para treinamento: 685.281 segundos\n",
      "y de validação\n",
      "['AT' 'CAT' 'BT' ... 'CT' 'ABT' 'BC']\n",
      "y de predição final\n",
      "['AT' 'CAT' 'CA' ... 'CT' 'BC' 'BC']\n",
      "- Acurácia no conjunto de validação: 48.10%\n",
      "- Tempo necessário para predição do conjunto de validação: 0.576 segundos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket, MiniRocketMultivariate\n",
    "\n",
    "print('\\n### Treinando com 10000 features (default)', sep='')\n",
    "transformation = MiniRocketMultivariate(random_state=42)\n",
    "model = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "signal, model_name = 'i', 'minirocket'\n",
    "for cycle in ['cycle_32']:\n",
    "    print('\\n---')\n",
    "    c = cycle.split('_')[-1]\n",
    "    if c == '1':\n",
    "        title = f'\\n## {c} Ciclo Pós Falta'\n",
    "    else:\n",
    "        title = f'\\n## 1/{c} Ciclo Pós Falta'\n",
    "    mean_acc, val_acc, train_time, val_time = training(signal, cycle, model, model_name, transformation, save=True)\n",
    "    row = f'\\n|{title.split(\" \")[1]}|10000|{mean_acc:.2f}|{val_acc:.2f}|{train_time}|{val_time}|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bc6884c7bbd22f1bda6f4218e2a6ec5e650e2e0dc8622ce5d2ea70b578015ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('mestrado': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
